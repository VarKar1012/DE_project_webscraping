# DE_project_webscraping

These projects demonstrate an ETL (Extract, Transform, Load) process using Python. The pipeline includes:
1. **Extracting** webpage content from a URL.
2. **Transforming** the extracted data.
3. **Loading** the data into a CSV/JSON file and into an SQLite3 database.
4. **Querying** the data in the SQLite3 database.

## Requirements

Before you begin, ensure you have met the following requirements:

- Python 3.x
- Required libraries: `requests`, `beautifulsoup4`, `pandas`, `sqlite3`

You can install the necessary libraries using:

```bash
pip install requests beautifulsoup4 pandas
